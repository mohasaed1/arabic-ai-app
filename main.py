from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import List, Dict
from openai import OpenAI
import requests
import os

# âœ… Globals
OPENAI_API_KEY = None
client = None

# âœ… App init
app = FastAPI()

# âœ… CORS for frontend access
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.on_event("startup")
def fetch_wp_openai_key():
    global OPENAI_API_KEY, client
    try:
        print("ğŸ”„ Fetching OpenAI key from WordPress...")
        response = requests.get(
            "https://gateofai.com/wp-json/gateofai/v1/openai-key",
            params={"token": "g8Zx12WvN43pDfK7LmTqY6bP9eAvJrCsXzM0HdQ2"},
            timeout=10
        )
        key = response.json().get("key")
        print("ğŸ”‘ Loaded API key from WP:", key)

        if key:
            OPENAI_API_KEY = key
            client = OpenAI(api_key=OPENAI_API_KEY)
            print("âœ… OpenAI client initialized.")
        else:
            print("âš ï¸ No key found in response.")
    except Exception as e:
        print("âŒ Error loading key:", e)

@app.get("/")
def home():
    return JSONResponse(content={"message": "ğŸš€ Arabic AI API is running!"})

@app.get("/debug-key")
def debug_key():
    return {
        "key_loaded": bool(OPENAI_API_KEY),
        "client_initialized": bool(client)
    }

class AnalysisRequest(BaseModel):
    query: str
    data: List[Dict]

@app.post("/analyze-text")
async def analyze_query(req: AnalysisRequest):
    if not client:
        return {"error": "OpenAI client not initialized."}

    try:
        sample_data = req.data[:5]  # only show GPT a sample for context
        prompt = (
            "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. "
            "Ø³Ø£Ø±Ø³Ù„ Ù„Ùƒ Ø¬Ø²Ø¡Ù‹Ø§ Ù…Ù† Ø¬Ø¯ÙˆÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¹ Ø³Ø¤Ø§Ù„Ù‡ØŒ "
            "Ø£Ø¬Ø¨ Ø¨Ø´ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚ ÙˆÙ…Ù‡Ù†ÙŠ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ ÙˆØ¥Ø°Ø§ ÙƒØ§Ù† Ù…Ù†Ø§Ø³Ø¨Ù‹Ø§ØŒ Ø§Ù‚ØªØ±Ø­ Ø§Ø³Ù… Ø¹Ù…ÙˆØ¯ Ù„Ø¹Ø±Ø¶Ù‡ Ø¨Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ.\n"
            f"Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n{sample_data}\n\nØ§Ù„Ø³Ø¤Ø§Ù„:\n{req.query}"
        )

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"},
                {"role": "user", "content": prompt}
            ]
        )

        return {"answer": response.choices[0].message.content}
    except Exception as e:
        return {"error": str(e)}

@app.post("/chat")
async def chat_with_gpt(request: Request):
    if not client:
        return {"error": "OpenAI client not initialized."}

    body = await request.json()
    message = body.get("message", "")
    if not message:
        return {"error": "Empty message."}

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": message}]
        )
        return {"reply": response.choices[0].message.content}
    except Exception as e:
        return {"error": str(e)}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=int(os.getenv("PORT", 8000)))
